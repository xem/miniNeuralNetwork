<script>

// Create a matrix:
// - filled with random numbers by default
// - filled with zero if z = 1
M = (r,c,z) => Array(r).fill().map(() => Array(c).fill(z ? 0 : Math.random() * 2 - 1));

// Operations on matrices:
// o === 0: addition (a+=b) (default)
// o === 1: subtraction (a-=b)
// o === 2: product (a*=b)
// o === 3: scale (a*=b, b is a scalar)
// o === 4: map (a=b(a), b is a function
// o === 6: dot product (r = a.b)
O = (a, b, o, r, i, j, k, l = "length") => {
  if(o === 6) r = M(a[l], b[0][l], 1); // dot product
  for(i = a[l]; i--;){
    for(j = a[0][l]; j--;){
      if(
        o === 6 || (( // dot
          a[i][j] = (
            o === 1 ? a[i][j] - b[i][j] // sub
            : o === 2 ? a[i][j] * b[i][j] // product
            : o === 3 ? a[i][j] * b // scale
            : o === 4 ? b(a[i][j]) // map
            : a[i][j] + b[i][j] // add
          )
        ), 0)
      ){
        for(k = b[0][l]; k--;){
          r[i][k] += a[i][j] * b[j][k]; // dot
        }
      }
    }
  }
  return r;
}

// Mini Neural Network
N = {

  // Init
  
  // Params:
  // - i: input nodes
  // - h: hidden nodes
  // - o: output nodes
  // - l: learning rate
  // - f: activation function (default: sigmoid)
  // - g: gradient descent function (default: y*(1-y))
  
  i: (i, h, o, l = 0.3, f = (x => 1 / (1 + Math.exp(-x))), g = (y => y * (1 - y))) => {
    
    // Save l, f, g for later
    N.l = l;
    N.f = f;
    N.g = g;

    // Generate random weights from input nodes to hidden nodes, and from hidden nodes to output nodes
    N.w = M(h, i); 
    N.W = M(o, h);

    // Generate random bias for hidden and output nodes
    N.b = M(h, 1);
    N.B = M(o, 1);
  },

  // Passthrough function
  // Used for both training and querying the network
  
  // Params: 
  // - input: input nodes
  // - target: desired output (for training) / undefined (for querying)
  p: (input, target, h, o) => {
    
    // Generate hidden nodes' outputs
    O(h = O(N.w, input, 6), N.b);
    
    // Activation function
    O(h, N.f, 4);

    // Generating output nodes' output
    O(o = O(N.W, h, 6), N.B);
    O(o, N.f, 4);
    
    // Query code ends here:
    if(!target) return o;

    // Training coninues here:
    // Calculate output nodes' error (target - output)
    O(target, o, 1);

    // Calculate output nodes' gradient
    O(o, N.g, 4);
    O(o, target, 2)
    O(o, N.l, 3);

    // Adjust hidden to output weights with deltas (output gradient x transposed hidden nodes)
    //console.log(h, O(h, 0));
    O(N.W, O(o, [h.flat()], 6));
    
    // Adjust bias with gradients
    O(N.B, o); 

    // Calculate hidden gradient, apply the hidden layer errors (transposed hidden to output weights x output nodes errors)
    O(h, N.g, 4);
    //console.log(N.W);
    O(h, O(N.W[0].map(z=>[z]), target, 6), 2);
    O(h, N.l, 3);

    // Adjust input to hidden weights with deltas (hidden gradient x transposed input)
    //console.log(input, O(input, 0));
    O(N.w, O(h, [input.flat()], 6));
    
    // Adjust the bias with gradients
    O(N.b, h);
  }
}

// Columnize an array ([a,b] => [[a],[b]])
C = a => a.map(z=>[z]);

// Demo
N.i(2,3,1);

console.log("Before training...");
console.log('0 AND 0',N.p(C([0,0]))[0][0]);
console.log('0 AND 1',N.p(C([0,1]))[0][0]);
console.log('1 AND 0',N.p(C([1,0]))[0][0]);
console.log('1 AND 1',N.p(C([1,1]))[0][0]);

training_data = [
  [[1,1], [1]],
  [[1,0], [0]],
  [[0,1], [0]],
  [[0,0], [0]],
];

// several training epochs
for(i = 0; i < 50000; i++){
  tdata = training_data[Math.floor(Math.random() * training_data.length)];
  N.p(C(tdata[0]), C(tdata[1]));
}

console.log("After training...");
console.log('0 AND 0',N.p(C([0,0]))[0][0]);
console.log('0 AND 1',N.p(C([0,1]))[0][0]);
console.log('1 AND 0',N.p(C([1,0]))[0][0]);
console.log('1 AND 1',N.p(C([1,1]))[0][0]);


// Demo 2
N.i(2,10,1);

console.log("Before training...");
console.log('0 XOR 0',N.p(C([0,0]))[0][0]);
console.log('0 XOR 1',N.p(C([0,1]))[0][0]);
console.log('1 XOR 0',N.p(C([1,0]))[0][0]);
console.log('1 XOR 1',N.p(C([1,1]))[0][0]);

training_data2 = [
  [[1,1], [0]],
  [[1,0], [1]],
  [[0,1], [1]],
  [[0,0], [0]],
];

// several training epochs
for(i = 0; i < 50000; i++){
  tdata = training_data2[Math.floor(Math.random() * training_data2.length)];
  N.p(C(tdata[0]), C(tdata[1]));
}

console.log("After training...");
console.log('0 XOR 0',N.p(C([0,0]))[0][0]);
console.log('0 XOR 1',N.p(C([0,1]))[0][0]);
console.log('1 XOR 0',N.p(C([1,0]))[0][0]);
console.log('1 XOR 1',N.p(C([1,1]))[0][0]);
</script>